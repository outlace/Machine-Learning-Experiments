{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A recursive neural network that decides how many times to run itself\n",
    "Produces variable-length outputs for static-length inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([[0],[0,0],[0,0,0],[0,0,0,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return np.matrix(1.0 / (1.0 + np.exp(-x)))\n",
    "\n",
    "def relu(x):\n",
    "    alpha = 0.01\n",
    "    return np.maximum(x, (alpha * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#initialize random weights\n",
    "numIn, numHid, numOut = 2, 3, 2\n",
    "theta1 = np.array( 0.5 * np.sqrt ( 6 / ( numIn + numHid) ) * np.random.randn( numIn + 1, numHid ), dtype=\"float32\" )\n",
    "theta2 = np.array( 0.5 * np.sqrt ( 6 / ( numHid + numOut ) ) * np.random.randn( numHid + 1, numOut ), dtype=\"float32\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "theta = np.append(theta1.flatten(), theta2.flatten()) #unroll vectors in a one long vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nn(x, theta):\n",
    "    i = 0\n",
    "    theta1 = np.array(theta[:9]).reshape(3,3)\n",
    "    theta2 = np.array(theta[9:]).reshape(4,2)\n",
    "    #print(theta1.shape)\n",
    "    #print(theta2.shape)\n",
    "    outputs = []\n",
    "    def comp(x):\n",
    "        #print(x)\n",
    "        a1 = np.array(np.concatenate((x.reshape(1,2), np.ones((1,1))), axis=1))\n",
    "        z2 = a1 @ theta1\n",
    "        a2 = np.concatenate((relu(z2), np.ones((1,1))), axis=1)\n",
    "        z3 = a2 @ theta2\n",
    "        a3 = sigmoid(z3)\n",
    "        return a3\n",
    "    \n",
    "    a3 = comp(x)\n",
    "    outputs.append(a3[0,1])\n",
    "    while a3[0,0] > 0.5 and i < 3: #prevent an infinite loop; constrain output length\n",
    "        i += 1\n",
    "        input = np.array([[a3[0,1],0]])\n",
    "        a3 = comp(input)\n",
    "        outputs.append(a3[0,1])\n",
    "    return np.array(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The neural network accepts an input vector of length 2. It has 2 output nodes. One node is used to control whether or not to recursively run itself, the other is the real data output. We simply threshold > 0.5 to trigger a recursive call to itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.62431196]\n",
      "[ 0.71118059]\n",
      "[ 0.60979257]\n",
      "[ 0.69732337]\n"
     ]
    }
   ],
   "source": [
    "###example output with random initial weights\n",
    "print( nn(X[0], theta) )\n",
    "print( nn(X[1], theta) ) \n",
    "print( nn(X[2], theta) ) \n",
    "print( nn(X[3], theta) ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function\n",
    "Arbitrarily assign a high cost to mismatches in the length of the output, then also assess MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def costFunction(X, Y, theta):\n",
    "    cost = 0\n",
    "    for i in range(len(X)):\n",
    "        y = Y[i]\n",
    "        m = float(len(X[i]))\n",
    "        hThetaX = nn(X[i], theta)\n",
    "        if len(y) != len(hThetaX):\n",
    "            cost += 3\n",
    "        else:\n",
    "            cost += (1/m) * np.sum(np.abs(y - hThetaX)**2)\n",
    "        \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Genetic Algorithm to Solve Weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brandonbrown/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:16: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/brandonbrown/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Sol'n:\n",
      "[[ 13.55        14.58        62.0889891   -6.4966617    7.16086276\n",
      "   -1.80259996   8.53635902   8.6205749  -10.54        -5.27       -13.5479922\n",
      "   -0.16212416  -9.13629965   8.46666441  10.39147747  27.13608853\n",
      "  -23.26767004]]\n",
      "Cost:0.835819518334\n"
     ]
    }
   ],
   "source": [
    "import random as rn, numpy as np\n",
    "# [Initial population size, mutation rate (=1%), num generations (30), solution length (13), # winners/per gen]\n",
    "initPop, mutRate, numGen, solLen, numWin = 100, 0.01, 500, 17, 20\n",
    "#initialize current population to random values within range\n",
    "curPop = np.random.choice(np.arange(-15,15,step=0.01),size=(initPop, solLen),replace=False)\n",
    "nextPop = np.zeros((curPop.shape[0], curPop.shape[1]))\n",
    "fitVec = np.zeros((initPop, 2)) #1st col is indices, 2nd col is cost\n",
    "for i in range(numGen): #iterate through num generations\n",
    "    #Create vector of all errors from cost function for each solution\n",
    "\tfitVec = np.array([np.array([x, np.sum(costFunction(X, y, curPop[x].T))]) for x in range(initPop)])\n",
    "\t#plt.pyplot.scatter(i,np.sum(fitVec[:,1]))\n",
    "\twinners = np.zeros((numWin, solLen))\n",
    "\tfor n in range(len(winners)): #for n in range(10)\n",
    "\t\tselected = np.random.choice(range(len(fitVec)), numWin/2, replace=False)\n",
    "\t\twnr = np.argmin(fitVec[selected,1])\n",
    "\t\twinners[n] = curPop[int(fitVec[selected[wnr]][0])]\n",
    "\tnextPop[:len(winners)] = winners #populate new gen with winners\n",
    "\tduplicWin = np.zeros((((initPop - len(winners))),winners.shape[1]))\n",
    "\tfor x in range(winners.shape[1]): #for each col in winners (3 cols)\n",
    "        #Duplicate winners (20x3 matrix) 3 times to create 80x3 matrix, then shuffle columns\n",
    "\t\tnumDups = ((initPop - len(winners))/len(winners)) #num times to duplicate to fill rest of nextPop\n",
    "\t\tduplicWin[:, x] = np.repeat(winners[:, x], numDups, axis=0)#duplicate each col\n",
    "\t\tduplicWin[:, x] = np.random.permutation(duplicWin[:, x]) #shuffle each col (\"crossover\")\n",
    "    #Populate the rest of the generation with offspring of mating pairs\n",
    "\tnextPop[len(winners):] = np.matrix(duplicWin)\n",
    "    #Create a mutation matrix, mostly 1s, but some elements are random numbers from a normal distribution\n",
    "\tmutMatrix = [np.float(np.random.normal(0,2,1)) if rn.random() < mutRate else 1 for x in range(nextPop.size)]\n",
    "    #randomly mutate part of the population by multiplying nextPop by our mutation matrix\n",
    "\tnextPop = np.multiply(nextPop, np.matrix(mutMatrix).reshape(nextPop.shape))\n",
    "\tcurPop = nextPop\n",
    "best_soln = curPop[np.argmin(fitVec[:,1])]\n",
    "print(\"Best Sol'n:\\n%s\\nCost:%s\" % (best_soln,np.sum(costFunction(X, y, best_soln.T))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.]\n",
      "[ 0.  0.]\n",
      "[ 0.77  0.    0.  ]\n",
      "[ 0.99  0.3   0.    0.  ]\n"
     ]
    }
   ],
   "source": [
    "#Demonstrate variable output after training\n",
    "print( np.round(nn(X[0], best_soln.reshape(17,1)), 2) )\n",
    "print( np.round(nn(X[1], best_soln.reshape(17,1)), 2) )\n",
    "print( np.round(nn(X[2], best_soln.reshape(17,1)), 2) )\n",
    "print( np.round(nn(X[3], best_soln.reshape(17,1)), 2) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
